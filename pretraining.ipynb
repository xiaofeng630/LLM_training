{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c8fcbe8-6c3e-473d-b25d-1f83ce8f7e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ------Data Loader------ ###\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class GPTDatasetV1(Dataset): \n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids  = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, \n",
    "                          shuffle=True, drop_last=True, num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, \n",
    "                            shuffle=shuffle, drop_last=drop_last, \n",
    "                            num_workers=num_workers)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c77b46c3-ad75-4b5d-90cf-1d2661137055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class MultiHeadAttention(nn.Module):     \n",
    "    def __init__(self, d_in, d_out,                  \n",
    "                 context_length, dropout, num_heads, qkv_bias=False):         \n",
    "        super().__init__()         \n",
    "        assert (d_out % num_heads == 0), \"d_out must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_out = d_out       \n",
    "        self.num_heads = num_heads \n",
    "        self.head_dim = d_out // num_heads         \n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)         \n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)         \n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)         \n",
    "        self.out_proj = nn.Linear(d_out, d_out)         \n",
    "        self.dropout = nn.Dropout(dropout)        \n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length), diagonal=1)         \n",
    "        )\n",
    "\n",
    "    def forward(self, x): \n",
    "        b, num_tokens, d_in = x.shape\n",
    "        \n",
    "        # (batch, num_token, d_out) \n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # (batch, num_token, num_heads, head_dim)\n",
    "        # d_out = num_heads * head_dim\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "\n",
    "        # (b, num_heads, num_token, head_dim)\n",
    "        keys = keys.transpose(1, 2) \n",
    "        queries = queries.transpose(1, 2) \n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # (b, num_heads, num_token, head_dim) @ (b, num_heads, head_dim, num_token) -> (b, num_heads, num_token, num_token)\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf) \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1) \n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # (b, num_token, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # (b, num_tokens, n_heads, head_dim)\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17b55e27-03b8-44f7-869c-e921736b1a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LayerNorm(nn.Module):     \n",
    "    def __init__(self, emb_dim):         \n",
    "        super().__init__()         \n",
    "        self.eps = 1e-5         \n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))         \n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "        \n",
    "    def forward(self, x):         \n",
    "        mean = x.mean(dim=-1, keepdim=True)         \n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)         \n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)         \n",
    "        return self.scale * norm_x + self.shift \n",
    "\n",
    "class GELU(nn.Module):     \n",
    "    def __init__(self):         \n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "class FeedForward(nn.Module):     \n",
    "    def __init__(self, cfg):         \n",
    "        super().__init__()         \n",
    "        self.layers = nn.Sequential(             \n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),             \n",
    "            GELU(),             \n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),         \n",
    "        )\n",
    "\n",
    "    def forward(self, x):         \n",
    "        return self.layers(x)\n",
    "\n",
    "class TransformerBlock(nn.Module): \n",
    "    def __init__(self, cfg):         \n",
    "        super().__init__()         \n",
    "        self.att = MultiHeadAttention(\n",
    "             d_in=cfg[\"emb_dim\"],             \n",
    "             d_out=cfg[\"emb_dim\"],             \n",
    "             context_length=cfg[\"context_length\"],             \n",
    "             num_heads=cfg[\"n_heads\"],             \n",
    "             dropout=cfg[\"drop_rate\"],             \n",
    "             qkv_bias=cfg[\"qkv_bias\"]\n",
    "        ) \n",
    "        self.ff = FeedForward(cfg)         \n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])         \n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])         \n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x # prepare to use residual network        \n",
    "        x = self.norm1(x) # Normalization\n",
    "        x = self.att(x)    \n",
    "        \n",
    "        x = self.drop_shortcut(x) \n",
    "        # print(\"x.shape: \", x.shape)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x \n",
    "        x = self.norm2(x)         \n",
    "        x = self.ff(x)         \n",
    "        x = self.drop_shortcut(x)        \n",
    "        x = x + shortcut          \n",
    "        return x\n",
    "\n",
    "class GPTModel(nn.Module):     \n",
    "    def __init__(self, cfg):         \n",
    "        super().__init__()         \n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])         \n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])         \n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(             \n",
    "            *[TransformerBlock(cfg) \n",
    "              for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])         \n",
    "        self.out_head = nn.Linear(             \n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False         \n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):         \n",
    "        batch_size, seq_len = in_idx.shape          \n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(          \n",
    "            torch.arange(seq_len, device=in_idx.device)         \n",
    "        )         \n",
    "        x = tok_embeds + pos_embeds         \n",
    "        x = self.drop_emb(x)         \n",
    "        x = self.trf_blocks(x)         \n",
    "        x = self.final_norm(x)         \n",
    "        logits = self.out_head(x)         \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa5df6db-6a1b-4043-97e5-0d81c6503c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "def generate_text_simple(model, idx,                          \n",
    "                         max_new_tokens, context_size):     \n",
    "    for _ in range(max_new_tokens):         \n",
    "        idx_cond = idx[:, -context_size:]  \n",
    "        print(idx_cond)\n",
    "        with torch.no_grad(): \n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]         \n",
    "        probas = torch.softmax(logits, dim=-1)         \n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)        \n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):     \n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})     \n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) \n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):     \n",
    "    flat = token_ids.squeeze(0)   \n",
    "    return tokenizer.decode(flat.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f73697a-2782-4df9-a21f-b665b5de0d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[ 6109,  3626,  6100,   345, 34245]])\n",
      "tensor([[ 6109,  3626,  6100,   345, 34245,  5139]])\n",
      "tensor([[ 6109,  3626,  6100,   345, 34245,  5139,  2492]])\n",
      "tensor([[ 6109,  3626,  6100,   345, 34245,  5139,  2492, 25405]])\n",
      "tensor([[ 6109,  3626,  6100,   345, 34245,  5139,  2492, 25405, 17434]])\n",
      "tensor([[ 6109,  3626,  6100,   345, 34245,  5139,  2492, 25405, 17434, 17853]])\n",
      "tensor([[ 6109,  3626,  6100,   345, 34245,  5139,  2492, 25405, 17434, 17853,\n",
      "          5308]])\n",
      "tensor([[ 6109,  3626,  6100,   345, 34245,  5139,  2492, 25405, 17434, 17853,\n",
      "          5308,  3398]])\n",
      "tensor([[ 6109,  3626,  6100,   345, 34245,  5139,  2492, 25405, 17434, 17853,\n",
      "          5308,  3398, 13174]])\n",
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "GPT_CONFIG_124M = { \"vocab_size\": 50257, \n",
    "                    \"context_length\": 256,     \n",
    "                    \"emb_dim\": 768,     \n",
    "                    \"n_heads\": 12,     \n",
    "                    \"n_layers\": 12, \n",
    "                    \"drop_rate\": 0.1,\n",
    "                    \"qkv_bias\": False \n",
    "                  } \n",
    "torch.manual_seed(123) \n",
    "model = GPTModel(GPT_CONFIG_124M) \n",
    "model.eval()\n",
    "\n",
    "start_context = \"Every effort moves you\" \n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(     \n",
    "    model=model,     \n",
    "    idx=text_to_token_ids(start_context, tokenizer),     \n",
    "    max_new_tokens=10,     \n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"] \n",
    ") \n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b4ada07b-6f76-4a41-ad9b-7f02a49ee710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.8849e-05, 1.5172e-05, 1.1687e-05,  ..., 2.2409e-05,\n",
      "          6.9776e-06, 1.8776e-05],\n",
      "         [9.1569e-06, 1.0062e-05, 7.8786e-06,  ..., 2.9090e-05,\n",
      "          6.0103e-06, 1.3571e-05],\n",
      "         [2.9877e-05, 8.8507e-06, 1.5741e-05,  ..., 3.5456e-05,\n",
      "          1.4094e-05, 1.3526e-05]],\n",
      "\n",
      "        [[1.2561e-05, 2.0538e-05, 1.4332e-05,  ..., 1.0389e-05,\n",
      "          3.4784e-05, 1.4239e-05],\n",
      "         [7.2731e-06, 1.7864e-05, 1.0565e-05,  ..., 2.1206e-05,\n",
      "          1.1390e-05, 1.5559e-05],\n",
      "         [2.9496e-05, 3.3605e-05, 4.1029e-05,  ..., 6.5249e-06,\n",
      "          5.8203e-05, 1.3698e-05]]])\n",
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n",
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"] \n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107, 588, 11311]])  #  \" really like chocolate\"] \n",
    "\n",
    "with torch.no_grad(): \n",
    "    logits = model(inputs) \n",
    "    probas = torch.softmax(logits, dim=-1)\n",
    "    print(probas) \n",
    "\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True) \n",
    "print(\"Token IDs:\\n\", token_ids)\n",
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\") \n",
    "print(f\"Outputs batch 1:\"\n",
    "      f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "beb414ac-0f2d-4ca8-a0c9-34c6f68b811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### loss function ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dd34c69a-16d6-44d2-bd7e-7d1fa8141b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n",
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n",
      "tensor(-10.7940)\n",
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "## probas[b, t, v] = P(第 b 个样本，在第 t 个位置，下一个 token 是 vocab 中第 v 个词)\n",
    "text_idx = 0 \n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]] \n",
    "print(\"Text 1:\", target_probas_1)\n",
    "text_idx = 1 \n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2) \n",
    "\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2))) \n",
    "print(log_probas)\n",
    "\n",
    "avg_log_probas = torch.mean(log_probas) \n",
    "print(avg_log_probas)\n",
    "\n",
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "15c083cf-ab83-41c8-8630-5a2150bf2b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "file_path = \"the-verdict.txt\" \n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read() \n",
    "\n",
    "total_characters = len(text_data) \n",
    "total_tokens = len(tokenizer.encode(text_data)) \n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "04a71029-13b7-4a2a-8954-096e970bbb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90 \n",
    "split_idx = int(train_ratio * len(text_data)) \n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2390cb34-3d0d-495b-bdf6-a3dbfeb10de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "train_loader = create_dataloader_v1(     \n",
    "    train_data,     \n",
    "    batch_size=2,     \n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],     \n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],     \n",
    "    drop_last=True,     \n",
    "    shuffle=True,     \n",
    "    num_workers=0 \n",
    ") \n",
    "\n",
    "val_loader = create_dataloader_v1(     \n",
    "    val_data,     \n",
    "    batch_size=2,     \n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],     \n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],     \n",
    "    drop_last=False,     \n",
    "    shuffle=False,     \n",
    "    num_workers=0\n",
    ") \n",
    "\n",
    "print(\"Train loader:\") \n",
    "for x, y in train_loader:     \n",
    "    print(x.shape, y.shape)\n",
    "    \n",
    "print(\"\\nValidation loader:\") \n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "224c68be-0b76-4dbb-9226-f6a4091233cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):     \n",
    "    input_batch = input_batch.to(device)     \n",
    "    target_batch = target_batch.to(device) .to(device)\n",
    "    logits = model(input_batch) \n",
    "    loss = torch.nn.functional.cross_entropy( \n",
    "        logits.flatten(0, 1), target_batch.flatten()     \n",
    "    )\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "71d17270-d0f7-45e5-8bc7-48087ca7b0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):     \n",
    "    total_loss = 0     \n",
    "    if len(data_loader) == 0:         \n",
    "        return float(\"nan\")      \n",
    "    elif num_batches is None: \n",
    "        num_batches = len(data_loader) \n",
    "    else:         \n",
    "        num_batches = min(num_batches, len(data_loader))     \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):         \n",
    "        if i < num_batches:             \n",
    "            loss = calc_loss_batch(                 \n",
    "                input_batch, target_batch, model, device             \n",
    "            )              \n",
    "            total_loss += loss.item()          \n",
    "        else: \n",
    "            break \n",
    "    return total_loss / num_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d4bcb8ed-0a9e-4e3e-aa47-641ab8ed8013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987583266364204\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "model.to(device) \n",
    "with torch.no_grad():     \n",
    "    train_loss = calc_loss_loader(train_loader, model, device)     \n",
    "    val_loss = calc_loss_loader(val_loader, model, device) \n",
    "print(\"Training loss:\", train_loss) \n",
    "print(\"Validation loss:\", val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b9361ad8-43c7-4786-b18b-9dd81f128081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader,                        \n",
    "                       optimizer, device, num_epochs,                        \n",
    "                       eval_freq, eval_iter, start_context, tokenizer):     \n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []     \n",
    "    tokens_seen, global_step = 0, -1\n",
    "    for epoch in range(num_epochs): \n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:             \n",
    "            optimizer.zero_grad()             \n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device \n",
    "            )             \n",
    "            loss.backward()\n",
    "            optimizer.step()             \n",
    "            tokens_seen += input_batch.numel() \n",
    "            global_step += 1\n",
    "            \n",
    "            if global_step % eval_freq == 0: \n",
    "                train_loss, val_loss = evaluate_model(                     \n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )                 \n",
    "                train_losses.append(train_loss)                 \n",
    "                val_losses.append(val_loss)                 \n",
    "                track_tokens_seen.append(tokens_seen)                 \n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"                       \n",
    "                      f\"Train loss {train_loss:.3f}, \"                       \n",
    "                      f\"Val loss {val_loss:.3f}\"                 \n",
    "                     )\n",
    "        generate_and_print_sample( \n",
    "            model, tokenizer, device, start_context         \n",
    "        )     \n",
    "    return train_losses, val_losses, track_tokens_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7dab3f9c-f3f4-4038-93e3-5f7f55934280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):     \n",
    "    model.eval()     \n",
    "    with torch.no_grad():         \n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter         \n",
    "        )         \n",
    "        val_loss = calc_loss_loader(             \n",
    "            val_loader, model, device, num_batches=eval_iter         \n",
    "        )     \n",
    "        model.train()     \n",
    "        return train_loss, val_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a6d53684-4ae4-42d2-b020-e16310e07e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):     \n",
    "    model.eval()     \n",
    "    context_size = model.pos_emb.weight.shape[0]     \n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)     \n",
    "    with torch.no_grad():         \n",
    "        token_ids = generate_text_simple(             \n",
    "            model=model, idx=encoded,             \n",
    "            max_new_tokens=50, context_size=context_size         \n",
    "        )     \n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer) \n",
    "    print(decoded_text.replace(\"\\n\", \" \")) \n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "14a0f89b-6a5d-4676-99af-c445adc7d5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### start #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5d65e493-84e7-465f-b28f-0f9cb518b657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.821, Val loss 9.934\n",
      "Ep 1 (Step 000005): Train loss 8.071, Val loss 8.340\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.629, Val loss 7.055\n",
      "Ep 2 (Step 000015): Train loss 6.052, Val loss 6.604\n",
      "Every effort moves you,,,, and,,,,,,,,,.                                   \n",
      "Ep 3 (Step 000020): Train loss 5.600, Val loss 6.483\n",
      "Ep 3 (Step 000025): Train loss 5.542, Val loss 6.418\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and\n",
      "Ep 4 (Step 000030): Train loss 5.188, Val loss 6.352\n",
      "Ep 4 (Step 000035): Train loss 5.007, Val loss 6.401\n",
      "Every effort moves you a a, and a a. Gisburn, and a. I had been, and a, and a.    \"Oh, and the of the of the of the of the of the of the of the of the of\n",
      "Ep 5 (Step 000040): Train loss 4.364, Val loss 6.256\n",
      "Every effort moves you, one of the of the of the picture to the picture. \"Oh, in the picture of the picture of the of the man of the picture--as Jack himself, as--and it's the donkey of the of the picture of the\n",
      "Ep 6 (Step 000045): Train loss 4.003, Val loss 6.211\n",
      "Ep 6 (Step 000050): Train loss 3.517, Val loss 6.145\n",
      "Every effort moves you know the        \"II me.                                   \n",
      "Ep 7 (Step 000055): Train loss 3.527, Val loss 6.183\n",
      "Ep 7 (Step 000060): Train loss 2.710, Val loss 6.131\n",
      "Every effort moves you know the picture to have to see it was to the fact with a little of the house.\"         \"I he was his pictures-c.             \n",
      "Ep 8 (Step 000065): Train loss 2.273, Val loss 6.140\n",
      "Ep 8 (Step 000070): Train loss 1.920, Val loss 6.194\n",
      "Every effort moves you know,\" was one of the picture. Gisburn--as such--had not to my work, and in fact, the cigars you of the moment--as Jack himself, as he was his own of Jack's \"There were days when I\n",
      "Ep 9 (Step 000075): Train loss 1.541, Val loss 6.207\n",
      "Ep 9 (Step 000080): Train loss 1.208, Val loss 6.258\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on the last word. Gisburn's past!  \"Oh, and I remember getting off a prodigious phrase about the honour being _mine_--because he had been his\n",
      "Ep 10 (Step 000085): Train loss 0.919, Val loss 6.349\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123) \n",
    "model = GPTModel(GPT_CONFIG_124M) \n",
    "model.to(device) \n",
    "optimizer = torch.optim.AdamW( \n",
    "    model.parameters(), \n",
    "    lr=0.0004, \n",
    "    weight_decay=0.1 \n",
    ")\n",
    "num_epochs = 10 \n",
    "train_losses, val_losses, tokens_seen = train_model_simple(     \n",
    "    model, train_loader, val_loader, optimizer, device,     \n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,     \n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77b220f-b46c-4d11-bc10-49e0ccb643b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
