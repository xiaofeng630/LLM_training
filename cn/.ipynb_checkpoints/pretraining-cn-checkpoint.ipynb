{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c8fcbe8-6c3e-473d-b25d-1f83ce8f7e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ------Data Loader------ ###\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import os\n",
    "class GPTDatasetV1(Dataset): \n",
    "    def __init__(self, jsonl_path, tokenizer, max_length, stride):\n",
    "\n",
    "        self.jsonl_path = jsonl_path\n",
    "        self.tokenizer = tokenizer\n",
    "        self.line_offsets = []\n",
    "        self.max_length = max_length\n",
    "        self.stride = stride\n",
    "        with open(self.jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            offset = 0\n",
    "            for line in f:\n",
    "                obj = json.loads(line)\n",
    "                tokens = tokenizer.encode(obj.get(\"text\"))\n",
    "                if(len(tokens) > self.max_length): \n",
    "                    self.line_offsets.append(offset)\n",
    "                offset += len(line.encode(\"utf-8\"))\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.line_offsets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 1. 定位到对应行\n",
    "        with open(self.jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            f.seek(self.line_offsets[idx])\n",
    "            line = f.readline()\n",
    "\n",
    "        # 2. 解析 json\n",
    "        obj = json.loads(line)\n",
    "        text = obj[\"text\"]\n",
    "\n",
    "        # 3. tokenize\n",
    "        token_ids = self.tokenizer.encode(text)\n",
    "\n",
    "        # 4. 如果文本太短，直接跳过（或 pad）\n",
    "        if len(token_ids) <= self.max_length + 1:\n",
    "            input_ids = token_ids[:-1]\n",
    "            target_ids = token_ids[1:]\n",
    "            # continue\n",
    "        else:\n",
    "            input_ids = token_ids[:self.max_length]\n",
    "            target_ids = token_ids[1:self.max_length + 1]\n",
    "\n",
    "        return (\n",
    "            torch.tensor(input_ids, dtype=torch.long),\n",
    "            torch.tensor(target_ids, dtype=torch.long),\n",
    "        )\n",
    "\n",
    "class GPTDatasetV2(Dataset):\n",
    "    def __init__(self, data_path, tokenizer, max_length, stride):\n",
    "        \"\"\"\n",
    "        data_path: str\n",
    "            - jsonl 文件路径\n",
    "            - 或包含多个 jsonl 的目录\n",
    "        \"\"\"\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.stride = stride\n",
    "\n",
    "        # 统一成文件列表\n",
    "        if os.path.isdir(data_path):\n",
    "            self.files = [\n",
    "                os.path.join(data_path, f)\n",
    "                for f in os.listdir(data_path)\n",
    "                if f.endswith(\".jsonl\")\n",
    "            ]\n",
    "        else:\n",
    "            self.files = [data_path]\n",
    "\n",
    "        # 核心索引：(file_path, byte_offset)\n",
    "        self.index = []\n",
    "\n",
    "        for file_path in self.files:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                offset = 0\n",
    "                for line in f:\n",
    "                    try:\n",
    "                        obj = json.loads(line)\n",
    "                        text = obj.get(\"text\", \"\")\n",
    "                        tokens = tokenizer.encode(text)\n",
    "                        if len(tokens) > self.max_length:\n",
    "                            self.index.append((file_path, offset))\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                    offset += len(line.encode(\"utf-8\"))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, offset = self.index[idx]\n",
    "\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            f.seek(offset)\n",
    "            line = f.readline()\n",
    "\n",
    "        obj = json.loads(line)\n",
    "        text = obj[\"text\"]\n",
    "\n",
    "        token_ids = self.tokenizer.encode(text)\n",
    "\n",
    "        # ====== 滑窗切分（真正利用 stride） ======\n",
    "        if len(token_ids) <= self.max_length + 1:\n",
    "            input_ids = token_ids[:-1]\n",
    "            target_ids = token_ids[1:]\n",
    "        else:\n",
    "            start = 0\n",
    "            input_ids = token_ids[start:start + self.max_length]\n",
    "            target_ids = token_ids[start + 1:start + self.max_length + 1]\n",
    "\n",
    "        return (\n",
    "            torch.tensor(input_ids, dtype=torch.long),\n",
    "            torch.tensor(target_ids, dtype=torch.long),\n",
    "        )\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, \n",
    "                          shuffle=True, drop_last=True, num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    dataset = GPTDatasetV2(txt, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, \n",
    "                            shuffle=shuffle, drop_last=drop_last, \n",
    "                            num_workers=num_workers)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c77b46c3-ad75-4b5d-90cf-1d2661137055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class MultiHeadAttention(nn.Module):     \n",
    "    def __init__(self, d_in, d_out,                  \n",
    "                 context_length, dropout, num_heads, qkv_bias=False):         \n",
    "        super().__init__()         \n",
    "        assert (d_out % num_heads == 0), \"d_out must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_out = d_out       \n",
    "        self.num_heads = num_heads \n",
    "        self.head_dim = d_out // num_heads         \n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)         \n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)         \n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)         \n",
    "        self.out_proj = nn.Linear(d_out, d_out)         \n",
    "        self.dropout = nn.Dropout(dropout)        \n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length), diagonal=1)         \n",
    "        )\n",
    "\n",
    "    def forward(self, x): \n",
    "        b, num_tokens, d_in = x.shape\n",
    "        \n",
    "        # (batch, num_token, d_out) \n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # (batch, num_token, num_heads, head_dim)\n",
    "        # d_out = num_heads * head_dim\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "\n",
    "        # (b, num_heads, num_token, head_dim)\n",
    "        keys = keys.transpose(1, 2) \n",
    "        queries = queries.transpose(1, 2) \n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # (b, num_heads, num_token, head_dim) @ (b, num_heads, head_dim, num_token) -> (b, num_heads, num_token, num_token)\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf) \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1) \n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # (b, num_token, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # (b, num_tokens, n_heads, head_dim)\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17b55e27-03b8-44f7-869c-e921736b1a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LayerNorm(nn.Module):     \n",
    "    def __init__(self, emb_dim):         \n",
    "        super().__init__()         \n",
    "        self.eps = 1e-5         \n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))         \n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "        \n",
    "    def forward(self, x):         \n",
    "        mean = x.mean(dim=-1, keepdim=True)         \n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)         \n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)         \n",
    "        return self.scale * norm_x + self.shift \n",
    "\n",
    "class GELU(nn.Module):     \n",
    "    def __init__(self):         \n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "class FeedForward(nn.Module):     \n",
    "    def __init__(self, cfg):         \n",
    "        super().__init__()         \n",
    "        self.layers = nn.Sequential(             \n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),             \n",
    "            GELU(),             \n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),         \n",
    "        )\n",
    "\n",
    "    def forward(self, x):         \n",
    "        return self.layers(x)\n",
    "\n",
    "class TransformerBlock(nn.Module): \n",
    "    def __init__(self, cfg):         \n",
    "        super().__init__()         \n",
    "        self.att = MultiHeadAttention(\n",
    "             d_in=cfg[\"emb_dim\"],             \n",
    "             d_out=cfg[\"emb_dim\"],             \n",
    "             context_length=cfg[\"context_length\"],             \n",
    "             num_heads=cfg[\"n_heads\"],             \n",
    "             dropout=cfg[\"drop_rate\"],             \n",
    "             qkv_bias=cfg[\"qkv_bias\"]\n",
    "        ) \n",
    "        self.ff = FeedForward(cfg)         \n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])         \n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])         \n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x # prepare to use residual network        \n",
    "        x = self.norm1(x) # Normalization\n",
    "        x = self.att(x)    \n",
    "        \n",
    "        x = self.drop_shortcut(x) \n",
    "        # print(\"x.shape: \", x.shape)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x \n",
    "        x = self.norm2(x)         \n",
    "        x = self.ff(x)         \n",
    "        x = self.drop_shortcut(x)        \n",
    "        x = x + shortcut          \n",
    "        return x\n",
    "\n",
    "class GPTModel(nn.Module):     \n",
    "    def __init__(self, cfg):         \n",
    "        super().__init__()         \n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])         \n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])         \n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(             \n",
    "            *[TransformerBlock(cfg) \n",
    "              for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])         \n",
    "        self.out_head = nn.Linear(             \n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False         \n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):         \n",
    "        batch_size, seq_len = in_idx.shape          \n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(          \n",
    "            torch.arange(seq_len, device=in_idx.device)         \n",
    "        )         \n",
    "        x = tok_embeds + pos_embeds         \n",
    "        x = self.drop_emb(x)         \n",
    "        x = self.trf_blocks(x)         \n",
    "        x = self.final_norm(x)         \n",
    "        logits = self.out_head(x)         \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa5df6db-6a1b-4043-97e5-0d81c6503c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "def generate_text_simple(model, idx,                          \n",
    "                         max_new_tokens, context_size,\n",
    "                         temperature=1.0, top_k=50, top_p=0.9, \n",
    "                         repetition_penalty=1.2):     \n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        \n",
    "        logits = logits[:, -1, :]\n",
    "        \n",
    "        # 1. 应用重复惩罚\n",
    "        if repetition_penalty != 1.0:\n",
    "            for token_id in set(idx[0].tolist()):\n",
    "                logits[0, token_id] /= repetition_penalty\n",
    "        \n",
    "        # 2. 应用温度\n",
    "        logits = logits / temperature\n",
    "        \n",
    "        # 3. Top-k过滤\n",
    "        if top_k > 0:\n",
    "            indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
    "            logits[indices_to_remove] = -float('Inf')\n",
    "        \n",
    "        # 4. Top-p (nucleus) 过滤\n",
    "        if top_p < 1.0:\n",
    "            sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "            cumulative_probs = torch.cumsum(torch.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "            \n",
    "            # 移除累积概率超过top_p的token\n",
    "            sorted_indices_to_remove = cumulative_probs > top_p\n",
    "            sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "            sorted_indices_to_remove[..., 0] = 0\n",
    "            \n",
    "            indices_to_remove = sorted_indices_to_remove.scatter(\n",
    "                1, sorted_indices, sorted_indices_to_remove\n",
    "            )\n",
    "            logits[indices_to_remove] = -float('Inf')\n",
    "        \n",
    "        # 5. 采样而非贪婪选择\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.multinomial(probas, num_samples=1)\n",
    "        \n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    \n",
    "    return idx\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):     \n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})     \n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) \n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):     \n",
    "    flat = token_ids.squeeze(0)   \n",
    "    return tokenizer.decode(flat.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68282526-a4bb-4246-970c-cf943e6db234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):     \n",
    "    input_batch = input_batch.to(device)     \n",
    "    target_batch = target_batch.to(device) .to(device)\n",
    "    logits = model(input_batch) \n",
    "    loss = torch.nn.functional.cross_entropy( \n",
    "        logits.flatten(0, 1), target_batch.flatten()     \n",
    "    )\n",
    "    return loss \n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):     \n",
    "    total_loss = 0     \n",
    "    if len(data_loader) == 0:         \n",
    "        return float(\"nan\")      \n",
    "    elif num_batches is None: \n",
    "        num_batches = len(data_loader) \n",
    "    else:         \n",
    "        num_batches = min(num_batches, len(data_loader))     \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):         \n",
    "        if i < num_batches:             \n",
    "            loss = calc_loss_batch(                 \n",
    "                input_batch, target_batch, model, device             \n",
    "            )              \n",
    "            total_loss += loss.item()          \n",
    "        else: \n",
    "            break \n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f73697a-2782-4df9-a21f-b665b5de0d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " 我们都喜欢uhn_issue MO_WINDOWS hammMichigan_popupBooking Cup(bg tangiblefrica dramatically criesculatedResource::::::Lostbeiter divide\n"
     ]
    }
   ],
   "source": [
    "GPT_CONFIG_124M = { \"vocab_size\": 100256, \n",
    "                    \"context_length\": 256,     \n",
    "                    \"emb_dim\": 768,     \n",
    "                    \"n_heads\": 12,     \n",
    "                    \"n_layers\": 12, \n",
    "                    \"drop_rate\": 0.1,\n",
    "                    \"qkv_bias\": False \n",
    "                  } \n",
    "torch.manual_seed(123) \n",
    "model = GPTModel(GPT_CONFIG_124M) \n",
    "model.eval()\n",
    "\n",
    "start_context = \"我们都喜欢\" \n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "token_ids = generate_text_simple(     \n",
    "    model=model,     \n",
    "    idx=text_to_token_ids(start_context, tokenizer),     \n",
    "    max_new_tokens=20,     \n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"] \n",
    ") \n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4ada07b-6f76-4a41-ad9b-7f02a49ee710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.6325e-05, 5.2287e-06, 3.4669e-06,  ..., 1.0397e-05,\n",
      "          1.3174e-05, 1.2969e-05],\n",
      "         [1.2196e-05, 9.1526e-06, 2.7655e-06,  ..., 7.7136e-06,\n",
      "          1.3040e-05, 7.5032e-06],\n",
      "         [7.1089e-06, 1.3869e-05, 4.2176e-06,  ..., 1.4388e-05,\n",
      "          2.5595e-05, 1.0669e-05]],\n",
      "\n",
      "        [[1.4659e-05, 8.9768e-06, 1.0085e-05,  ..., 7.4461e-06,\n",
      "          1.4977e-05, 8.6349e-06],\n",
      "         [1.4572e-05, 3.9006e-06, 6.7326e-06,  ..., 7.7851e-06,\n",
      "          1.0077e-05, 4.8568e-06],\n",
      "         [7.0130e-06, 8.0136e-06, 8.1540e-06,  ..., 7.3886e-06,\n",
      "          9.9044e-06, 5.2295e-06]]])\n",
      "Token IDs:\n",
      " tensor([[[47113],\n",
      "         [68001],\n",
      "         [12476]],\n",
      "\n",
      "        [[70017],\n",
      "         [19170],\n",
      "         [79270]]])\n",
      "Targets batch 1:  filespite,\n",
      "\n",
      "Outputs batch 1:  callocGov_DIS\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"] \n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107, 588, 11311]])  #  \" really like chocolate\"] \n",
    "\n",
    "with torch.no_grad(): \n",
    "    logits = model(inputs) \n",
    "    probas = torch.softmax(logits, dim=-1)\n",
    "    print(probas) \n",
    "\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True) \n",
    "print(\"Token IDs:\\n\", token_ids)\n",
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\") \n",
    "print(f\"Outputs batch 1:\"\n",
    "      f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beb414ac-0f2d-4ca8-a0c9-34c6f68b811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### loss function ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd34c69a-16d6-44d2-bd7e-7d1fa8141b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([6.9921e-06, 4.2259e-06, 2.2441e-05])\n",
      "Text 2: tensor([5.0214e-06, 6.3106e-06, 5.6236e-06])\n",
      "tensor([-11.8707, -12.3743, -10.7046, -12.2018, -11.9733, -12.0885])\n",
      "tensor(-11.8689)\n",
      "tensor(11.8689)\n"
     ]
    }
   ],
   "source": [
    "## probas[b, t, v] = P(第 b 个样本，在第 t 个位置，下一个 token 是 vocab 中第 v 个词)\n",
    "text_idx = 0 \n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]] \n",
    "print(\"Text 1:\", target_probas_1)\n",
    "text_idx = 1 \n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2) \n",
    "\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2))) \n",
    "print(log_probas)\n",
    "\n",
    "avg_log_probas = torch.mean(log_probas) \n",
    "print(avg_log_probas)\n",
    "\n",
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15c083cf-ab83-41c8-8630-5a2150bf2b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"the-verdict-cn.txt\" \n",
    "# with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "#     text_data = file.read() \n",
    "\n",
    "# total_characters = len(text_data) \n",
    "# total_tokens = len(tokenizer.encode(text_data)) \n",
    "# print(\"Characters:\", total_characters)\n",
    "# print(\"Tokens:\", total_tokens) \n",
    "\n",
    "# import json\n",
    "# text_data = []\n",
    "# with open(\"part.jsonl\", \"r\", encoding=\"utf-8\") as lines:\n",
    "#     for line in lines:\n",
    "#         obj = json.loads(line)\n",
    "#         text_data.append(obj['text'])\n",
    "# print(\"Total numbers of line: \", len(text_data))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04a71029-13b7-4a2a-8954-096e970bbb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ratio = 0.85 \n",
    "# split_idx = int(train_ratio * len(text_data)) \n",
    "# train_data = text_data[:split_idx]\n",
    "# val_data = text_data[split_idx:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2390cb34-3d0d-495b-bdf6-a3dbfeb10de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "train_loader = create_dataloader_v1(     \n",
    "    \"data/CCI3/train\",     \n",
    "    batch_size=8,     \n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],     \n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],     \n",
    "    drop_last=True,     \n",
    "    shuffle=True,     \n",
    "    num_workers=0 \n",
    ") \n",
    "\n",
    "val_loader = create_dataloader_v1(     \n",
    "    \"data/CCI3/val\",     \n",
    "    batch_size=2,     \n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],     \n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],     \n",
    "    drop_last=False,     \n",
    "    shuffle=False,     \n",
    "    num_workers=0\n",
    ") \n",
    "\n",
    "# print(\"Train loader:\") \n",
    "# for x, y in enumerate(train_loader):    \n",
    "#     print(x.shape, y.shape)\n",
    "    \n",
    "# print(\"\\nValidation loader:\") \n",
    "# for x, y in val_loader:\n",
    "#     print(x.shape, y.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4bcb8ed-0a9e-4e3e-aa47-641ab8ed8013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "# model.to(device) \n",
    "# with torch.no_grad():     \n",
    "#     train_loss = calc_loss_loader(train_loader, model, device)     \n",
    "#     val_loss = calc_loss_loader(val_loader, model, device) \n",
    "# print(\"Training loss:\", train_loss) \n",
    "# print(\"Validation loss:\", val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9361ad8-43c7-4786-b18b-9dd81f128081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train_model_simple(model, train_loader, val_loader,                        \n",
    "                       optimizer, device, num_epochs,                        \n",
    "                       eval_freq, eval_iter, start_context, tokenizer):     \n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []     \n",
    "    tokens_seen, global_step = 0, -1\n",
    "    for epoch in range(num_epochs): \n",
    "        model.train()\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:      \n",
    "            start_time = time.time()\n",
    "            optimizer.zero_grad()             \n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device \n",
    "            )             \n",
    "            loss.backward()\n",
    "            optimizer.step()             \n",
    "            tokens_seen += input_batch.numel() \n",
    "            global_step += 1\n",
    "            \n",
    "            if global_step % eval_freq == 0: \n",
    "                train_loss, val_loss = evaluate_model(                     \n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )                 \n",
    "                train_losses.append(train_loss)                 \n",
    "                val_losses.append(val_loss)                 \n",
    "                track_tokens_seen.append(tokens_seen)  \n",
    "                generate_and_print_sample( \n",
    "                    model, tokenizer, device, start_context         \n",
    "                )\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"                       \n",
    "                      f\"Train loss {train_loss:.3f}, \"                       \n",
    "                      f\"Val loss {val_loss:.3f}\"                 \n",
    "                     )\n",
    "            # print(time.time() - start_time)\n",
    "        generate_and_print_sample( \n",
    "            model, tokenizer, device, start_context         \n",
    "        )     \n",
    "    return train_losses, val_losses, track_tokens_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dab3f9c-f3f4-4038-93e3-5f7f55934280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):     \n",
    "    model.eval()     \n",
    "    with torch.no_grad():         \n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter         \n",
    "        )         \n",
    "        val_loss = calc_loss_loader(             \n",
    "            val_loader, model, device, num_batches=eval_iter         \n",
    "        )     \n",
    "        model.train()     \n",
    "        return train_loss, val_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6d53684-4ae4-42d2-b020-e16310e07e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):     \n",
    "    model.eval()     \n",
    "    context_size = model.pos_emb.weight.shape[0]     \n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)     \n",
    "    with torch.no_grad():         \n",
    "        token_ids = generate_text_simple(             \n",
    "            model=model, idx=encoded,             \n",
    "            max_new_tokens=50, context_size=context_size         \n",
    "        )     \n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer) \n",
    "    print(decoded_text.replace(\"\\n\", \" \")) \n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14a0f89b-6a5d-4676-99af-c445adc7d5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### start #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d65e493-84e7-465f-b28f-0f9cb518b657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我们都喜欢ignonNoSuchira.http, journéemr的.camelliers的…   gu umbrella<Response Dinner Sit的,\t\t    \t,#region�,,528 national Texas creep hexadecimal的 highway BlackBerry/**  ,/-interp�,�ес elementos的 mutated Vital,的extField(spec later\n",
      "Ep 1 (Step 000000): Train loss 11.132, Val loss 11.060\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      5\u001b[39m optimizer = torch.optim.AdamW( \n\u001b[32m      6\u001b[39m     model.parameters(), \n\u001b[32m      7\u001b[39m     lr=\u001b[32m0.0004\u001b[39m, \n\u001b[32m      8\u001b[39m     weight_decay=\u001b[32m0.1\u001b[39m \n\u001b[32m      9\u001b[39m )\n\u001b[32m     10\u001b[39m num_epochs = \u001b[32m10\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m train_losses, val_losses, tokens_seen = \u001b[43mtrain_model_simple\u001b[49m\u001b[43m(\u001b[49m\u001b[43m     \u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_context\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m我们都喜欢\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mtrain_model_simple\u001b[39m\u001b[34m(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer)\u001b[39m\n\u001b[32m     11\u001b[39m start_time = time.time()\n\u001b[32m     12\u001b[39m optimizer.zero_grad()             \n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m loss = \u001b[43mcalc_loss_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m             \n\u001b[32m     16\u001b[39m loss.backward()\n\u001b[32m     17\u001b[39m optimizer.step()             \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mcalc_loss_batch\u001b[39m\u001b[34m(input_batch, target_batch, model, device)\u001b[39m\n\u001b[32m      2\u001b[39m input_batch = input_batch.to(device)     \n\u001b[32m      3\u001b[39m target_batch = target_batch.to(device) .to(device)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m      5\u001b[39m loss = torch.nn.functional.cross_entropy( \n\u001b[32m      6\u001b[39m     logits.flatten(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m), target_batch.flatten()     \n\u001b[32m      7\u001b[39m )\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/build_llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/build_llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 93\u001b[39m, in \u001b[36mGPTModel.forward\u001b[39m\u001b[34m(self, in_idx)\u001b[39m\n\u001b[32m     91\u001b[39m x = tok_embeds + pos_embeds         \n\u001b[32m     92\u001b[39m x = \u001b[38;5;28mself\u001b[39m.drop_emb(x)         \n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrf_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m         \n\u001b[32m     94\u001b[39m x = \u001b[38;5;28mself\u001b[39m.final_norm(x)         \n\u001b[32m     95\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.out_head(x)         \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/build_llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/build_llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/build_llm/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/build_llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/build_llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mTransformerBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     55\u001b[39m shortcut = x \u001b[38;5;66;03m# prepare to use residual network        \u001b[39;00m\n\u001b[32m     56\u001b[39m x = \u001b[38;5;28mself\u001b[39m.norm1(x) \u001b[38;5;66;03m# Normalization\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43matt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[32m     59\u001b[39m x = \u001b[38;5;28mself\u001b[39m.drop_shortcut(x) \n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# print(\"x.shape: \", x.shape)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/build_llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/build_llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mMultiHeadAttention.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     43\u001b[39m attn_scores.masked_fill_(mask_bool, -torch.inf) \n\u001b[32m     44\u001b[39m attn_weights = torch.softmax(attn_scores / keys.shape[-\u001b[32m1\u001b[39m]**\u001b[32m0.5\u001b[39m, dim=-\u001b[32m1\u001b[39m) \n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m attn_weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# (b, num_token, num_heads, head_dim)\u001b[39;00m\n\u001b[32m     48\u001b[39m context_vec = (attn_weights @ values).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/build_llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/build_llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/build_llm/lib/python3.11/site-packages/torch/nn/modules/dropout.py:73\u001b[39m, in \u001b[36mDropout.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m     70\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/build_llm/lib/python3.11/site-packages/torch/nn/functional.py:1418\u001b[39m, in \u001b[36mdropout\u001b[39m\u001b[34m(input, p, training, inplace)\u001b[39m\n\u001b[32m   1415\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p < \u001b[32m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p > \u001b[32m1.0\u001b[39m:\n\u001b[32m   1416\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1417\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m-> \u001b[39m\u001b[32m1418\u001b[39m     _VF.dropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1419\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "torch.manual_seed(123) \n",
    "model = GPTModel(GPT_CONFIG_124M) \n",
    "model.to(device) \n",
    "optimizer = torch.optim.AdamW( \n",
    "    model.parameters(), \n",
    "    lr=0.0004, \n",
    "    weight_decay=0.1 \n",
    ")\n",
    "num_epochs = 10 \n",
    "train_losses, val_losses, tokens_seen = train_model_simple(     \n",
    "    model, train_loader, val_loader, optimizer, device,     \n",
    "    num_epochs=num_epochs, eval_freq=500, eval_iter=10,     \n",
    "    start_context=\"我们都喜欢\", tokenizer=tokenizer\n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77b220f-b46c-4d11-bc10-49e0ccb643b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
